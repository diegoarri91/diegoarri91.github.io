---
title: "Rescuing neural spike train models from bad MLE"
layout: post
date: 2020-01-01 00:00
tag: jekyll
image: https://sergiokopplin.github.io/indigo/assets/images/jekyll-logo-light-solid.png
headerImage: true
projects: true
hidden: true # don't count this post in blog pagination
category: project
author: diego.arri
externalLink: true
link: false
description: "
Developed a framework to improve samples generated by autoregressive models by minimizing 
an alternative metric. I developed a PyTorch library to perform the optimization. The work was 
published in NeurIPS 2020.
[<a href = https://proceedings.neurips.cc/paper/2020/hash/186b690e29892f137b4c34cfa40a3a4d-Abstract.html target=_blank>Paper</a>]
[<a href = https://github.com/diegoarri91/mmd-glm.git target=_blank>Github</a>]
"
---

The standard approach to fitting time series autoregressive models is to condition 
on the training data at each time step and perform maximum likelihood estimation (MLE). 
However, MLE often leads to models that perform poorly when generating samples recursively for
more than one time step. In one of my PhD projects, we proposed to fit an autoregressive model 
by minimizing the Maximum Mean Discrepancy between the training data and model generated
samples using. I wrote a library to perform the optimization in PyTorch and the work was 
published in NeurIPS 2020.
[<a href = https://proceedings.neurips.cc/paper/2020/hash/186b690e29892f137b4c34cfa40a3a4d-Abstract.html target=_blank>Paper</a>]
[<a href = https://github.com/diegoarri91/mmd-glm.git target=_blank>Github</a>]